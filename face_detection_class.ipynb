{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Haar-cascade Detection in OpenCV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "location of haarcascades:\n",
    "\n",
    "```bash\n",
    "$ /Users/myusername/miniconda3/envs/my_enviroment/share/OpenCV/haarcascades\n",
    "```\n",
    "or just download from git and place in directory:\n",
    "\n",
    "https://github.com/opencv/opencv/tree/master/data/haarcascades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **scaleFactor**: How much the image size is reduced at each image scale. This value is used to create the scale pyramid in order to detect faces at multiple scales in the image (some faces may be closer to the fore-ground, and thus be larger; other faces may be smaller and in the background, thus the usage of varying scales). A value of 1.05 indicates that Jeremy is reducing the size of the image by 5% at each level in the pyramid.\n",
    "\n",
    "\n",
    "- __minNeighbors__: How many neighbors each window should have for the area in the window to be considered a face. The cascade classiﬁer will detect multiple windows around a face. This parameter controls how many rectangles (neighbors) needto be detected for the window to be labeled a face.\n",
    "\n",
    "\n",
    "- __minSize__: A tuple of width and height (in pixels) indicating the minimum size of the window. Bounding boxes smaller than this size are ignored. It is a good idea to start with (30, 30) and ﬁne-tune from there.\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "class FaceDetector:\n",
    "    def __init__(self, faceCascadePath):\n",
    "        # load the face detector\n",
    "        self.faceCascade = cv2.CascadeClassifier(faceCascadePath)\n",
    "        \n",
    "    def detect(self, image, scaleFactor = 1.1, minNeighbors = 5, minSize = (30, 30)):\n",
    "        # detect faces in the image\n",
    "        rects = self.faceCascade.detectMultiScale(image,\n",
    "        scaleFactor = scaleFactor, minNeighbors = minNeighbors,\n",
    "        minSize = minSize, flags = cv2.CASCADE_SCALE_IMAGE)\n",
    "\n",
    "        # return the rectangles representing bounding\n",
    "        # boxes around the faces\n",
    "        return rects\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "class FaceDetector:\n",
    "    def __init__(self, faceCascadePath):\n",
    "        # load the face detector\n",
    "        self.faceCascade = cv2.CascadeClassifier(faceCascadePath)\n",
    "        \n",
    "    def detect(self, image, scaleFactor = 1.1, minNeighbors = 5, minSize = (30, 30)):\n",
    "        # detect faces in the image\n",
    "        rects = self.faceCascade.detectMultiScale(image,\n",
    "                                                  scaleFactor = scaleFactor, \n",
    "                                                  minNeighbors = minNeighbors,\n",
    "                                                  minSize = minSize, \n",
    "                                                  flags = cv2.CASCADE_SCALE_IMAGE)\n",
    "\n",
    "        # return the rectangles representing bounding\n",
    "        # boxes around the faces\n",
    "        return rects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('images/afghan-girl.jpg')      # load image\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)      # convert image to RGB and save it\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)    # create a grayscale of the image and save it  as gray\n",
    "\n",
    "\n",
    "fd = FaceDetector(\"haarcascades/haarcascade_frontalface_default.xml\")\n",
    "faceRects = fd.detect(gray, scaleFactor = 1.05, minNeighbors=10, minSize = (10,10))\n",
    "\n",
    "for (x,y, w, h) in faceRects:\n",
    "    cv2.rectangle(img, (x,y), (x+ w, y + h), (0,255,0), 2)\n",
    "    \n",
    "       \n",
    "plt.figure(figsize=(20,10))       # change the figure size to 20 by 10\n",
    "plt.imshow(img)   # display \n",
    "plt.show()                        # display image onto jupyter notebook cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Multiple faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('images/for_sale.jpg')  # load image\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # NEW VARIABLE grayscale original image \n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # convert to RGB\n",
    "\n",
    "\n",
    "fd = FaceDetector(\"haarcascades/haarcascade_frontalface_default.xml\")\n",
    "faceRects = fd.detect(gray, scaleFactor = 1.1, minNeighbors=5, minSize = (30,30))\n",
    "\n",
    "for (x,y, w, h) in faceRects:\n",
    "    cv2.rectangle(img, (x,y), (x+ w, y + h), (0,255,0), 2)\n",
    "    \n",
    "    \n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('images/messi2.png')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "fd = FaceDetector(\"haarcascades/haarcascade_frontalface_default.xml\")\n",
    "faceRects = fd.detect(gray, scaleFactor = 1.1, minNeighbors=5, minSize = (30,30))\n",
    "\n",
    "for (x,y, w, h) in faceRects:\n",
    "    cv2.rectangle(img, (x,y), (x+ w, y + h), (0,255,0), 2)\n",
    "    \n",
    "       \n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.imshow(img),plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "In most cases, the offending culprit will be the scaleFactor parameter. In other cases it may be minNeighbors. But as a debugging rule, start with the scaleFactor, adjust it as needed, and then move on to minNeighbors.\n",
    "\n",
    "**change**\n",
    "```python\n",
    "    faceRects = fd.detect(gray, scaleFactor = 1.2, minNeighbors=5, minSize = (30,30))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('images/messi2.png')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "fd = FaceDetector(\"haarcascades/haarcascade_frontalface_default.xml\")\n",
    "faceRects = fd.detect(gray, scaleFactor = 1.2, minNeighbors=5, minSize = (30,30))\n",
    "\n",
    "for (x,y, w, h) in faceRects:\n",
    "    cv2.rectangle(img, (x,y), (x+ w, y + h), (0,255,0), 2)\n",
    "    \n",
    "       \n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.imshow(img),plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('images/mfaces.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "fd = FaceDetector(\"haarcascades/haarcascade_frontalface_default.xml\")\n",
    "faceRects = fd.detect(gray, scaleFactor = 1.1, minNeighbors=5, minSize = (30,30))\n",
    "\n",
    "for (x,y, w, h) in faceRects:\n",
    "    cv2.rectangle(img, (x,y), (x+ w, y + h), (0,255,0), 2)\n",
    "    \n",
    "       \n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.imshow(img),plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
